**基于时间序列对金融数据的异常检测感知的研究**

# 摘要：

随着金融科技的快速发展和数字化转型的深入推进，金融机构的IT基础设施产生了海量的运营数据（非交易型数据），包括系统日志、API性能指标、数据质量度量、批处理作业状态以及OpenTelemetry标准下的分布式追踪数据等。这些运营数据呈现出典型的大规模时序特征：数据量可达百万至亿级样本、具有明显的时间依赖性和周期性模式（日周期、周周期、季节性）、存在概念漂移现象（数据分布随时间变化）、并对实时性要求极高。运营数据中的异常往往预示着系统故障、性能劣化、数据质量问题或潜在的安全风险，若不能及时发现和处理，将严重影响业务连续性和用户体验，甚至导致重大经济损失和监管合规问题。
传统的基于规则和阈值的异常检测方法在面对多维、非线性、动态变化的运营数据时表现出明显的局限性：规则难以穷尽所有异常模式、阈值设置依赖人工经验且无法自适应调整、难以平衡误报率和漏报率。采用无监督机器学习算法进行自动化异常检测成为金融机构亟待解决的关键技术挑战。

关键词：异常检测；金融运营数据；Open Telemetry
中图分类号：   文献标识码：  

# Research on Anomaly Detection and Perception of Financial Data Based on Time Series

Diao Yong
(Library and Archives, Dalian Maritime University, Dalian, Liaoning 116026)

# Abstract:
With the rapid advancement of fintech and the deepening of digital transformation, financial institutions' IT infrastructure generates massive amounts of operational data (non-transactional data). This includes system logs, API performance metrics, data quality measurements, batch job statuses, and distributed tracing data under the Open Telemetry standard. This operational data exhibits typical large-scale time-series characteristics: data volumes reaching millions to billions of samples, pronounced time dependency and periodic patterns (daily cycles, weekly cycles, seasonality), conceptual drift (data distribution shifts over time), and extremely high real-time requirements. Anomalies in operational data often signal system failures, performance degradation, data quality issues, or potential security risks. Failure to detect and address these promptly can severely impact business continuity and user experience, potentially leading to significant financial losses and regulatory compliance issues.
Traditional rule-based and threshold-based anomaly detection methods exhibit significant limitations when applied to multidimensional, nonlinear, and dynamically changing operational data: rules cannot exhaustively cover all anomaly patterns; threshold settings rely on manual expertise and lack adaptive adjustment capabilities; and false positive and false negative rates are difficult to balance. Implementing unsupervised machine learning algorithms for automated anomaly detection has become a critical technological challenge that financial institutions urgently need to address.

Keywords: Anomaly Detection; Financial Operations Data; Open Telemetry

# 1. 引言(Introduction)

金融机构 IT 系统生成的运营数据（系统日志、API 性能、数据质量指标等）呈现高维时序特征和极度不平衡分布（异常样本少于 5%）。传统基于规则和阈值的方法在应对动态环境时，面临规则维护成本高、静态阈值误报率高、高维特征交互难以覆盖等问题。本文提出基于多层混合策略的无监督异常检测框架，通过快速筛选、深度分析和自适应融合三阶段分析，在保持高召回率的同时降低误报率和计算成本开销。

# 2. 传统异常检测方法的局限性与挑战

在金融运营数据场景中，传统的基于规则和固定阈值的异常检测方法面临以下关键挑战：

- 规则维护成本高昂： 传统方法依赖人工定义的业务规则（如“CPU使用率>80%持续5分钟触发告警”），但金融系统的复杂度不断提升，规则数量呈指数级增长。据统计，大型金融机构的监控规则数量可达数万条，维护成本极高且容易产生规则冲突。
- 静态阈值难以适应动态环境： 金融业务存在明显的周期性和季节性特征（如月末、季末、年末的批处理高峰），静态阈值无法自适应这些变化，导致在正常业务高峰期产生大量误报（False Positives），造成“告警疲劳”（Alert Fatigue），降低运维团队的响应效率。
- 高维数据的“维度灾难”： 现代金融系统的可观测性数据维度极高（可达数百至上千维特征），传统规则难以覆盖特征间的复杂交互关系。例如，单独的“API延迟高”或“数据库查询慢”可能不足以判定异常，但两者同时出现且伴随特定的流量模式时，则很可能预示着严重的系统问题。
- 人工标注数据稀缺： 在运营监控场景中，获取高质量的标注异常数据（Labeled Data）成本极高，且异常类型多样、分布不均衡（异常样本通常占比不到1-5%），使得监督学习方法难以有效应用。

因此，全自动、高精度、可解释的无监督异常检测技术成为金融机构迫切需要攻克的技术难题。


# 3. 运营数据的核心特征

金融运营数据 (Financial Operational Data) 区别于交易数据 (Transactional Data)，主要指金融机构IT基础设施和业务系统在运行过程中产生的监控、日志、度量数据。这类数据呈现出显著的时间序列特性，数据点按时间顺序生成且相邻时间点之间存在强相关性。系统负载在工作时间和非工作时间的差异清晰可见，同时存在多层次的周期性模式，包括日周期的24小时循环、工作日与周末的周周期差异、月初月中月末的业务高峰月周期，以及财报季和审计季带来的年度周期性。长期观察这些数据往往能发现明显的趋势性，例如随着业务规模增长，系统负载呈现持续上升的态势。

运营数据的单个监控对象通常包含数十至数百个监控指标，而整个系统级别的特征维度可达数千。这些数据类型涵盖连续型数值如CPU使用率和内存占用、离散型计数如错误次数和请求数、以及类别型标签如日志级别和服务状态。不同指标之间的量纲差异极大，响应时间以毫秒为单位，而吞吐量可能达到万级QPS，这种差异性使得数据标准化成为必不可少的预处理步骤。

大型金融机构每天产生的运营日志和监控数据可达TB至PB级别，样本数量从百万级到亿级不等。这些数据以流式方式持续产生，对采集、传输和处理的实时性要求达到秒级甚至亚秒级。传统的单机处理能力已远不能满足需求，必须依赖分布式存储和计算框架来应对这种规模的数据处理挑战。

概念漂移 (Concept Drift) 是运营数据面临的另一个关键问题。数据分布并非静态不变，而是随时间动态演化。系统升级、业务扩展、架构调整都会导致正常数据的统计特性发生改变，新的异常类型如新型攻击手段和未知故障模式也在不断出现，使得基于历史数据训练的模型可能逐渐失效。这要求检测模型必须具备在线学习或增量更新能力，能够自适应地跟随数据分布的变化。

运营数据中的噪声与不确定性进一步增加了异常检测的难度。传感器误差、网络抖动、采样偏差等因素导致数据存在固有噪声。更棘手的是，异常的定义本身具有主观性，不同业务场景对异常的容忍度各不相同，且缺乏权威的标注基准。此外，正常样本远多于异常样本的类别不平衡现象普遍存在，异常占比通常低于5%，这使得传统分类方法容易偏向多数类而忽视异常模式的识别。

# 4 标准化与形式化定义以及策略分析

## 4.1 异常类型的形式化定义

根据Chandola等人的经典分类框架（IEEE TKDE 2009）和金融运营场景的实际需求，本文将异常分为三大类：

**点异常 (Point Outliers / Global Outliers)**

点异常指在多维特征空间中，单个数据点是显著偏离正常数据的个体分布。这是最常见的异常类型，判断标准是数据点的异常得分是否超过预设阈值。点异常的检测不考虑时间顺序和上下文信息，仅着重于单点的统计偏离程度。在金融运营场景中，点异常经常出现。例如，某个交易日上下午2点，核心交易系统的一台服务器CPU使用率从平时的50%左右突然跃升到95%。这种明显偏离正常运行区间的单点数据是典型的点异常，这类异常预示着系统正在经历突发故障或遭受攻击。

**情境异常 (Contextual Outliers / Conditional Outliers)**

情境异常的特殊之处在于数据点在特定上下文中间表现异常，但在全局或其它上下文中间可能完全正常。这里的上下文通常由时间、空间或业务场景等条件变量定义。情境异常的识别需要同时满足两个条件：在特定上下文中的异常得分超过上下文阈值，但是全局异常得分并未超过全局阈值。金融机构的运营数据中充斥着这类与时间强相关的异常。某大型银行的批处理系统在每月最后一个工作日晚上都会经历交易量和计算负载的高峰，这是月末对账和结算的正常业务模式，但如果在月中某个平常工作日的深夜出现同等规模的批处理负载，则明显是不符合业务规律。

**集合异常 (Collective Outliers / Pattern Outliers)**

集合异常指数据点的一组连续或相关的数据点整体表现出的异常模式，即使这些数据点单独来看可能都在正常范围内。集合异常的判定依据是整个子序列的综合得分，而非单个点的得分。这是三类异常中检测难度最高的，因为需要同时考虑数据点之间的时间序列、空间关联或逻辑关联关系。在实际运营中，集合异常往往比单点异常更加隐蔽和危险。数据库团队可能观察到SQL查询的出现频率在过去一周内持续攀升，尽管每次查询的执行时间都在5秒以内的可接受范围，但这种趋势性的累积预示着系统资源或数据库瓶颈问题。网络安全团队面对的DDoS攻击也是典型的集合异常，每个HTTP请求单独看都是合法的，但当数万个请求在短时间内集中到达时，其时序模式就暴露了攻击特征。

# 5. 算法描述与实际应用

## 5.1 分层异常检测策略算法概述

我们基于金融领域业务特点，设计了一个结合统计、卷积和循环网络优势的多层混合检测策略算法。该策略旨在结合快速筛选（统计/传统机器学习方法）和深度上下文建模（混合深度学习模型）的优势，以提高检测的准确性和对复杂异常模式（如局部异常和片段异常）的敏感性。采用基于重构/预测误差的深度学习范式作为核心，辅以传统邻近度检测，并通过加权融合机制得出最终的异常分数。

我们设计的策略包含三个主要阶段：

| 阶段 | 目的 | 推荐算法类别 | 算法优势利用 |
| :--- | :--- | :--- | :--- |
| 阶段 1：快速初筛 | 识别全局显著离群点，提供快速、可解释的初筛分数。 | 统计模型 / 传统机器学习 | 速度快、可解释性强（如 KNN, Isolation Forest） |
| 阶段 2：深度上下文分析 | 捕捉局部特征和长期时间依赖性，进行精细的上下文异常建模。 | 混合深度学习（CNN-RNN，GRU，Transformer等等）| 结合深度模型提取局部模式和捕捉时间依赖关系的能力 |
| 阶段 3：策略整合与决策 | 融合两层分数，通过动态阈值进行最终的异常判定。 | 集成/阈值优化 | 融合不同模型对异常的互补视图。|

## 数学公式与实现框架

### 阶段 1：全局点异常分数 $A_1$ (基于 k-近邻，KNN)

快速检测全局显著离群点（Point Outliers），即在数据空间中与其邻居距离过远的孤立点。KNN 是一种经典的邻近度（Proximity-Based）方法。KNN 能够高效地识别出数据空间中稀疏区域的点，这些点对于金融运营数据中的瞬时、剧烈波动非常敏感。采用 $k$ 个最近邻居的平均距离作为异常分数（AvgKNN），这比仅使用第 $k$ 个邻居的距离（kthNN）更为稳健。

对于 $t$ 时刻的多元数据点 $x_t \in \mathbb{R}^D$，其异常分数 $A_1(x_t)$ 定义为其到 $k$ 个最近邻居的平均距离：

$$
A_1(x_t) = \frac{1}{k} \sum_{j=1}^{k} d(x_t, x_t^{(j)})
$$

其中 $d(\cdot, \cdot)$ 是距离度量，在金融运营数据常用欧氏距离（$L_2$ 范数）或马氏距离（Mahalanobis Distance，用于考虑特征间的协方差）。

### 阶段 2：深度上下文异常分数 $A_2$ (基于 GRU 重构误差)

GRU 单元简化了 LSTM 的结构，将输入门和遗忘门耦合为一个更新门（Update gate），并将状态向量 $c$ 和 $h$ 合并为一个向量 $h$。GRU 的核心数学运算包括 `sigmoid` 激活函数（用于门控）和 `tanh` 激活函数。GRU可以识别复杂的情境异常（Contextual Outliers）和集合异常（Collective Outliers）。这些异常依赖于序列的时间依赖性（temporal dependencies）和上下文。我们利用门控循环单元（Gated Recurrent Unit, GRU）构建一个序列自编码器（AutoEncoder, AE）或变分自编码器（Variational AutoEncoder, VAE）。GRU 是长短期记忆网络（LSTM）的简化版本，在处理长序列时同样高效且计算要求更低。GRU-VAE（例如 OmniAnomaly）或 GRU-AE 模型专门用于学习正常时间序列的复杂数据分布。

模型输入是一个包含 $L$ 个时间步的滑动窗口 $W_t = (x_{t-L+1}, \dots, x_t)$。采用重构误差作为异常分数 $A_2$。模型在正常数据上训练，对异常数据（偏离正常模式的数据）进行重构时，将产生较大的误差。$A_2(W_t)$ 是原始窗口 $W_t$ 与 GRU-AE 重构输出 $\hat{W}_t$ 之间的平均均方误差（MSE）：
$$
A_2(W_t) = \text{MSE}(W_t, \hat{W}_t) = \frac{1}{L \cdot D} \sum_{i=0}^{L-1} \|x_{t-i} - \hat{x}_{t-i}\|_2^2
$$

其中 $L$ 是窗口长度，$D$ 是特征维度。$x_{t-i}$ 和 $\hat{x}_{t-i}$ 分别是原始数据和重构数据。$\|\cdot\|_2^2$ 是欧氏距离平方（$L_2$ 范数）。

### 阶段 3：多层整合与最终决策 $S_{\text{final}}$

我们的策略将快速邻近度分数 $A_1$ 和深度上下文分数 $A_2$ 进行融合，以确保系统同时具备点异常的高敏感度和序列模式异常的精确识别能力。借鉴 SALAD (Stochastic Adversarial Learned Anomaly Detection) 的集成思想。SALAD 的最终异常分数 $\mathcal{S}$ 是重构误差（$L_1$ 范数，$\|x - \hat{x}\|_1$）和判别误差（$\mathcal{D}(\hat{x})$）的加权和。

首先对两阶段分数进行归一化（Min-Max Scaling），使其位于 $[0, 1]$ 范围内，保证融合的公平性。

$$
\text{Normalize}(A) = \frac{A - \min(A)}{\max(A) - \min(A)}
$$

然后将归一化后的分数进行加权求和：

$$
S_{\text{final}}(x_t) = \alpha \cdot \text{Normalize}(A_1(x_t)) + (1 - \alpha) \cdot \text{Normalize}(A_2(W_t))
$$

其中，$\alpha \in [0, 1]$ 是权重超参数。较高的 $\alpha$ 值侧重于全局点异常检测（KNN），较低的值则侧重于时序上下文异常检测（GRU-AE）。

最终的异常决策 $D_{\text{final}}$ 是通过将融合分数 $S_{\text{final}}$ 与动态阈值 $\phi$ 进行比较来确定的。阈值 $\phi$ 可以根据训练集上的异常分布（例如，使用 $3\sigma$ 原则或基于污染率 $r$ 的百分位数）来自动确定。

$$
D_{\text{final}}(x_t) = \begin{cases} 1 & \text{if } S_{\text{final}}(x_t) \geq \phi \\ 0 & \text{otherwise} \end{cases}
$$

### 实现框架总结

该框架将KNN这种经典机器学习方法（速度较快，适用于初筛）与基于 GRU 的深度学习模型（擅长建模时序复杂性）相结合，有效应对金融运营数据中存在的多种异常类型。这种集成策略在当前时间序列异常检测研究中被广泛认可，能够提供比单一算法更鲁棒的性能。


## 5.2 算法分析总结

我们在公开数据集上验证了两组组合策略的有效性：IForest+CNN-LSTM 和 KNN+GRU。实验数据包含 4981 个样本点（15 维特征），其中 73 个异常点（占比约 1.5%）。滑动窗口设置为 20，权重参数 \alpha=\beta=0.5。

IForest+CNN-LSTM 组合的核心优势在于快速全局筛选。iForest 在 0.36 秒内完成训练和评分，迅速识别出空间上孤立的点异常。CNN-LSTM 自编码器训练耗时约 240 秒 (CPU) 或 23 秒 (GPU)，通过卷积层提取局部时序特征，LSTM 层捕捉长期依赖关系。该组合在 GPU 加速下取得 AUC-ROC 0.87，召回率 0.92 的成绩，适合对漏报率敏感的场景。但精确率仅为 0.08，意味着高误报率给运维带来负担。

KNN+GRU 组合采用 KNN 近邻距离作为初步分辨，训练耗时 1.3 秒。GRU 自编码器相比 LSTM 结构更简洁，训练时间为 484 秒 (CPU) 或 23 秒 (GPU)。GPU 加速版本表现最佳：AUC-ROC 达到 0.81、F1 值 0.47、精确率 0.41、召回率 0.56。这组指标明显优于 iForest+CNN-LSTM 的 F1 值 0.15 和精确率 0.08，证明 KNN+GRU 在精确率和召回率之间取得了更好的平衡。可视化结果显示，KNN 在第一阶段对突变点敏感，GRU 在第二阶段对缓慢漂移和周期性偏离有较强捕捉能力。

深度学习模型在GPU训练速度提升 10-21 倍，使得反覆调参和模型迭代成为可能。值得注意的是，KNN+GRU 在 GPU 环境下各项指标均有提升,相比CPU版本AUC-ROC从 0.76 升至 0.81，可能是因为更快的训练允许模型在相同 epoch 内达到更优的收敛状态。

在我们实际项目中，会根据业务复杂度选择模型，对于核心交易系统监控，可以接受较高误报率但不能遗漏真实故障，iForest+CNN-LSTM 的高召回率更合适。对于一般运营监控场景，KNN+GRU 的均衡性能在有限的人力下提供更高的告警质量。权重参数 \alpha 和 \beta 需根据需要衡量历史数据动态调整。

## 5.3 异常检测监控平台搭建

为支撑多层混合异常检测算法在生产环境的落地应用，需要构建一个端到端的异常监控平台。该平台采用OpenTelemetry作为统一的数据采集规范，将分布式系统中的追踪、日志和指标数据标准化提取。OpenTelemetry提供了与语言和厂商无关的可观测性框架，能够自动捕获应用程度的运行行为，并将其转换为结构化的运营数据，通过在各个服务节点部署OpenTelemetry Collector，系统可以实时收集包括请求延迟、错误率、资源利用率等在内的多维运营指标，这些指标经过标准化处理后形成了本文所使用的15维特征向量。数据采集完成后，所有运营信息汇入Kafka消息队列中同时实现解耦和缓冲。异常检测模块从Kafka消费实时数据流进行检测和报警。

所有经过检测的原始数据和异常评分最终持久化到数据湖（Data Lake）。数据湖不仅为运维团队提供了历史异常的回溯查询能力，还支持数据科学团队进行更复杂的离线分析。数据湖中的结构化数据可以直接对接商业智能工具，生成异常趋势报表、算法性能监控面板等可视化输出，为管理层的决策提供数据支撑。

# 6. 结论(Conclusion)

本文针对金融运营数据的异常检测需求，系统性研究了多层混合异常检测算法在多维时间序列上的适用性和性能表现。这个算法利用了不同算法的固有特点：简单统计方法提供高效率和基本可解释性，而深度学习混合模型则专注于复杂和上下文相关的异常模式。通过融合它们的输出，可以创建一个更加鲁棒和全面的检测系统。

在工程实践层面，本文设计了基于opentelemetry和Kafka事件驱动的分布式监控平台架构，通过消息驱动机制实现了数据采集，流式异常检测和数据湖存储的完整解决方案。研究成果不仅为金融运营数据的实时异常监控提供了理论基础和技术支撑，也为其他业务领域的多维时间序列异常检测提供了借鉴。。


# 参考文献(References)

Cost of Data Center Outages: 
https://www.vertiv.com/globalassets/documents/reports/2016-cost-of-data-center-outages-11-11_51190_1.pdf

Chandola V, Banerjee A, Kumar V. Anomaly detection: a survey. ACM Comput Surv, 2009, 41: 1–58

IEEE TKDE：Transactions on Knowledge and Data Engineering
https://dl.acm.org/journal/ieeecs_tkde

PyOD 2: A Python Library for Outlier Detection with LLM-powered Model Selection https://www.arxiv.org/abs/2412.12154

What is Opentelemetry: https://opentelemetry.io/docs/what-is-opentelemetry/

