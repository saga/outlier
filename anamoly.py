import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, precision_recall_curve
import warnings
warnings.filterwarnings('ignore')

import tensorflow as tf

from pyod.models.iforest import IForest
from pyod.models.lof import LOF
from pyod.models.pca import PCA
from pyod.models.knn import KNN
from pyod.models.copod import COPOD
from pyod.models.auto_encoder import AutoEncoder
from pyod.models.ocsvm import OCSVM
from pyod.models.ecod import ECOD

# å¯¼å…¥æ·±åº¦å­¦ä¹ æ¨¡å‹
try:
    from pyod.models.auto_encoder import AutoEncoder
    AUTOENCODER_AVAILABLE = True
except ImportError:
    AUTOENCODER_AVAILABLE = False
# try:
#     from pyod.models.deep_svdd import DeepSVDD
# except ImportError:
#     print("DeepSVDDä¾èµ–ç¼ºå¤±, è·³è¿‡DeepSVDDæ¨¡å‹")
#     AUTOENCODER_AVAILABLE = False

import time
from datetime import datetime, timedelta


def generate_financial_operational_data(n_samples=10000, n_features=15, contamination=0.05):

    # ç”Ÿæˆé‡‘èè¿è¥æ•°æ® + OpenTelemetry æœåŠ¡å™¨é“¾è·¯ç›‘æ§æ•°æ®

    # æŒ‡æ ‡è¯´æ˜ï¼ˆ15ç»´ç‰¹å¾ï¼‰ï¼š
    # ä¼ ç»Ÿè¿è¥æŒ‡æ ‡ï¼ˆTraditional Operational Metricsï¼‰:
    # - API å“åº”æ—¶é—´(ms) -> API Response Time
    # - æ‰¹å¤„ç†å»¶æ—¶(ms) -> Batch Processing Delay
    # - é”™è¯¯ç‡(%) -> Error Rate
    # - ååé‡(records/min) -> Throughput
    # - CPU ä½¿ç”¨ç‡(%) -> CPU Usage
    # - å†…å­˜ä½¿ç”¨ç‡(%) -> Memory Usage
    # - æ•°æ®è´¨é‡è¯„åˆ†(0-100) -> Data Quality Score
    # - å¹¶å‘è¿æ¥æ•° -> Concurrent Connections

    # OpenTelemetry æœåŠ¡æŒ‡æ ‡ï¼ˆServer-side Metricsï¼‰:
    # - HTTP å¹³å‡å“åº”æ—¶é—´(ms) -> HTTP Request Latency P95
    # - CPU å³°å€¼ -> CPU Peak Usage
    # - æœåŠ¡è°ƒç”¨æŒç»­æ—¶é—´ -> Service Trace Duration
    # - é˜Ÿåˆ—æ—¶å»¶(ms) -> Queue latency
    # - Span Duration(ms) -> Distributed Trace Span Duration
    # - æ¯ç§’æŸ¥è¯¢æ•°(QPS) -> Service Queries Per Second
    # - HTTP é”™è¯¯ç‡(%) -> HTTP 5xx Error Rate

    np.random.seed(42)

    # æ­£å¸¸æ•°æ®
    n_normal = int(n_samples * (1 - contamination))
    n_anomaly = n_samples - n_normal

    # æ­£å¸¸é«˜æ–¯æ•°æ® - å¤šç»´æ­£æ€åˆ†å¸ƒ
    normal_data = np.random.randn(n_normal, n_features)

    # ä¼ ç»Ÿè¿è¥æŒ‡æ ‡å’ŒæœåŠ¡å™¨æŒ‡æ ‡é€é¡¹è°ƒæ•´åˆ†å¸ƒ
    # ç‰¹å¾ç»´åº¦æ˜ å°„ï¼ˆ0-7ï¼‰ï¼š
    # Feature 0: API å“åº”æ—¶é—´(50-200ms)
    normal_data[:, 0] = np.abs(normal_data[:, 0] * 30 + 125)

    # Feature 1: æ‰¹å¤„ç†å»¶æ—¶ (1-10s)
    normal_data[:, 1] = np.abs(normal_data[:, 1] * 2 + 5)

    # Feature 2: é”™è¯¯ç‡ (0-2%)
    normal_data[:, 2] = np.abs(normal_data[:, 2] * 0.5 + 1)

    # Feature 3: ååé‡ (800-1200 records/min)
    normal_data[:, 3] = np.abs(normal_data[:, 3] * 100 + 1000)

    # Feature 4: CPU ä½¿ç”¨ç‡ (30-70%)
    normal_data[:, 4] = np.abs(normal_data[:, 4] * 10 + 50)

    # Feature 5: å†…å­˜ä½¿ç”¨ç‡ (40-80%)
    normal_data[:, 5] = np.abs(normal_data[:, 5] * 10 + 60)

    # Feature 6: æ•°æ®è´¨é‡åˆ† (70-100)
    normal_data[:, 6] = np.abs(normal_data[:, 6] * 3 + 92)

    # Feature 7: å¹¶å‘è¿æ¥æ•° (50-200)
    normal_data[:, 7] = np.abs(normal_data[:, 7] * 25 + 100)

    # OpenTelemetry æœåŠ¡å™¨æŒ‡æ ‡ï¼ˆ8-14ï¼‰
    # Feature 8: HTTP å“åº” P95 (80-200ms)
    normal_data[:, 8] = np.abs(normal_data[:, 8] * 35 + 125)

    # Feature 9: CPU å³°å€¼(85-98%)
    normal_data[:, 9] = np.abs(normal_data[:, 9] * 10 + 27.5)

    # Feature 10: æœåŠ¡é˜Ÿåˆ—æ·±åº¦(5-20)
    normal_data[:, 10] = np.abs(normal_data[:, 10] * 3 + 9.6)

    # Feature 11: åˆ†å¸ƒå¼è¿½è¸ªè€—æ—¶(100-180ms)
    normal_data[:, 11] = np.abs(normal_data[:, 11] * 20 + 65)

    # Feature 12: Trace Span Duration (20-150ms)
    normal_data[:, 12] = np.abs(normal_data[:, 12] * 30 + 85)

    # Feature 13: QPS æ¯ç§’è°ƒç”¨é‡(800-1500 queries/sec)
    normal_data[:, 13] = np.abs(normal_data[:, 13] * 350 + 1260)

    # Feature 14: HTTP 5xx é”™è¯¯ç‡ (0-3%)
    normal_data[:, 14] = np.abs(normal_data[:, 14] * 0.1 + 0.25)


    # ç”Ÿæˆå¼‚å¸¸æ•°æ®ï¼ˆå¤šæºï¼‰
    # æç«¯å¼‚å¸¸ï¼šå®Œå…¨éšæœºå™ªå£°å¼‚å¸¸ï¼ˆ30%ï¼‰
    n_extreme = int(n_anomaly * 0.3)
    extreme_anomaly = np.random.randn(n_extreme, n_features) * 3 + 5
    
    # ç±»å‹2 å±€éƒ¨å¼‚å¸¸ï¼šéƒ¨åˆ†æŒ‡æ ‡åç§»å¼‚å¸¸ï¼ˆ30%ï¼‰
    n_local = int(n_anomaly * 0.3)
    local_anomaly = np.random.randn(n_local, n_features)
    # éšæœºé€‰æ‹©2ï½3ä¸ªç‰¹å¾ä¸ºå¼‚å¸¸
    for i in range(n_local):
        anomaly_features = np.random.choice(n_features, size=np.random.randint(2, 4), replace=False)
        local_anomaly[i, anomaly_features] *= 4

    # ç±»åˆ«3ï¼šæœåŠ¡ç«¯æ€§èƒ½åŠ£åŒ–å¼‚å¸¸ï¼ˆ20%ï¼‰ - æ¨¡æ‹ŸæœåŠ¡é™çº§
    n_service = int(n_anomaly * 0.2)
    service_anomaly = np.random.randn(n_service, n_features)

    # å‰8ä¸ªç‰¹å¾æ­£å¸¸
    for j in range(8):
        if j == 0:
            service_anomaly[:, j] = service_anomaly[:, j] * 30 + 125
        elif j == 1:
            service_anomaly[:, j] = np.abs(service_anomaly[:, j] * 2 + 5)
        elif j == 2:
            service_anomaly[:, j] = np.abs(service_anomaly[:, j] * 0.5 + 1)
        elif j == 3:
            service_anomaly[:, j] = service_anomaly[:, j] * 100 + 1000
        elif j == 4:
            service_anomaly[:, j] = service_anomaly[:, j] * 10 + 50
        elif j == 5:
            service_anomaly[:, j] = service_anomaly[:, j] * 10 + 60
        elif j == 6:
            service_anomaly[:, j] = service_anomaly[:, j] * 3 + 92
        elif j == 7:
            service_anomaly[:, j] = service_anomaly[:, j] * 25 + 100

    # OpenTelemetry æœåŠ¡ä¾§æŒ‡æ ‡å¼‚å¸¸ï¼ˆ8-14ï¼‰
    service_anomaly[:, 8]  = np.abs(service_anomaly[:, 8]  * 100 + 500)   # HTTP P95å»¶è¿Ÿé«˜
    service_anomaly[:, 9]  = np.abs(service_anomaly[:, 9]  * 15  + 90)    # æ•°æ®å³°å€¼é«˜
    service_anomaly[:, 10] = np.abs(service_anomaly[:, 10] * 25  + 50)    # é˜Ÿåˆ—æ—¶å»¶å‡é«˜
    service_anomaly[:, 11] = np.abs(service_anomaly[:, 11] * 30  + 100)   # Trace è€—æ—¶å˜é«˜
    service_anomaly[:, 12] = np.abs(service_anomaly[:, 12] * 40  + 150)   # Span Durationé•¿
    service_anomaly[:, 13] = np.abs(service_anomaly[:, 13] * 300 + 900)   # QPSä½ï¼ˆæœåŠ¡å™¨é™çº§ï¼‰
    service_anomaly[:, 14] = np.abs(service_anomaly[:, 14] * 2   + 5)     # 5xxé”™è¯¯ç‡é«˜

    # ç±»åˆ«4ï¼šç³»ç»Ÿçº§æ•…éšœå¼‚å¸¸ï¼ˆ20%ï¼‰
    n_pattern = n_anomaly - n_extreme - n_local - n_service
    pattern_anomaly = np.random.randn(n_pattern, n_features)
    pattern_anomaly = pattern_anomaly * 2 + np.array([
        150, 5, 3, 900, 55, 60, 98, 100,
        800, 500, 30, 100, 200, 1000, 10   # OpenTelemetryæœåŠ¡ç«¯æŒ‡æ ‡å¼‚å¸¸
    ])

    # åˆå¹¶æ•°æ®
    X = np.vstack([normal_data, extreme_anomaly, local_anomaly, service_anomaly, pattern_anomaly])
    y = np.hstack([np.zeros(n_normal), np.ones(n_anomaly)])

    # æ‰“ä¹±æ•°æ®
    indices = np.random.permutation(n_samples)
    X, y = X[indices], y[indices]

    # åˆ›å»ºç‰¹å¾åç§°ï¼ˆä¸­æ–‡å¯¹åº”ï¼‰
    feature_names = [
        # ä¼ ç»Ÿè¿è¥æŒ‡æ ‡ (Traditional Operational Metrics)
        'API_Response_Time_ms',      # APIå“åº”æ—¶é—´(æ¯«ç§’)
        'Processing_Delay_sec',      # æ‰¹å¤„ç†å»¶è¿Ÿ(ç§’)
        'Error_Rate_pct',            # é”™è¯¯ç‡(%)
        'Throughput_records_min',    # ååé‡(è®°å½•/åˆ†é’Ÿ)
        'CPU_Usage_pct',             # CPUä½¿ç”¨ç‡(%)
        'Memory_Usage_pct',          # å†…å­˜ä½¿ç”¨ç‡(%)
        'Data_Quality_Score',        # æ•°æ®è´¨é‡è¯„åˆ†
        'Concurrent_Connections',    # å¹¶å‘è¿æ¥æ•°

        # OpenTelemetry æœåŠ¡ä¾§æŒ‡æ ‡ (Server-side Metrics)
        'HTTP_P95_Latency_ms',       # HTTPè¯·æ±‚P95å»¶è¿Ÿ(æ¯«ç§’)
        'Peak_CPU_pct',              # CPUå³°å€¼(%)
        'Queue_Duration_ms',         # æ•°æ®é˜Ÿåˆ—æ—¶å»¶(æ¯«ç§’)
        'Cache_Hit_Ratio_pct',       # ç¼“å­˜å‘½ä¸­ç‡(%)
        'Span_Duration_ms',          # åˆ†å¸ƒå¼è¿½è¸ªSpanæ—¶é•¿(æ¯«ç§’)
        'Service_QPS',               # æœåŠ¡æŸ¥è¯¢ç‡ (QPS)
        'HTTP_5xx_Error_Rate_pct'    # HTTP 5xxé”™è¯¯ç‡(%)
    ]

    return X, y, feature_names


def generate_time_series_features(X, timestamps=None):
    """
    ç”Ÿæˆæ—¶åºç‰¹å¾ - é’ˆå¯¹å¤§è§„æ¨¡æ—¶åºé‡‘èæ•°æ®
    Time-series feature engineering for large-scale financial data
    """
    n_samples = X.shape[0]

    # å¦‚æœæ²¡æœ‰æä¾›æ—¶é—´æˆ³ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ—¶é—´æˆ³ (æ¯åˆ†é’Ÿä¸€ä¸ªæ•°æ®ç‚¹)
    if timestamps is None:
        start_time = datetime(2025, 1, 1)
        timestamps = [start_time + timedelta(minutes=i) for i in range(n_samples)]

    # æå–æ—¶é—´ç‰¹å¾
    time_features = pd.DataFrame({
        'hour': [t.hour for t in timestamps],
        'day_of_week': [t.weekday() for t in timestamps],
        'day_of_month': [t.day for t in timestamps],
        'is_weekend': [1 if t.weekday() >= 5 else 0 for t in timestamps],
        'is_business_hour': [1 if 9 <= t.hour < 18 else 0 for t in timestamps],
    })

    # å‘¨æœŸæ€§ç¼–ç  (sin/cos å˜æ¢é¿å…è¾¹ç•Œä¸è¿ç»­)
    time_features['hour_sin'] = np.sin(2 * np.pi * time_features['hour'] / 24)
    time_features['hour_cos'] = np.cos(2 * np.pi * time_features['hour'] / 24)
    time_features['day_sin'] = np.sin(2 * np.pi * time_features['day_of_week'] / 7)
    time_features['day_cos'] = np.cos(2 * np.pi * time_features['day_of_week'] / 7)

    # æ»‘åŠ¨çª—å£ç»Ÿè®¡ç‰¹å¾ (æ•è·æ—¶åºä¾èµ–)
    window_sizes = [5, 10, 30]  # 5åˆ†é’Ÿã€10åˆ†é’Ÿã€30åˆ†é’Ÿçª—å£
    X_df = pd.DataFrame(X)

    for col in range(X.shape[1]):
        for window in window_sizes:
            # ç§»åŠ¨å¹³å‡
            time_features[f'feature_{col}_ma_{window}'] = X_df[col].rolling(window=window, min_periods=1).mean()
            # ç§»åŠ¨æ ‡å‡†å·®
            time_features[f'feature_{col}_std_{window}'] = X_df[col].rolling(window=window, min_periods=1).std().fillna(0)

    # åˆå¹¶åŸå§‹ç‰¹å¾å’Œæ—¶åºç‰¹å¾
    X_combined = np.hstack([X, time_features.values])

    return X_combined, time_features.columns.tolist()


def evaluate_time_series_performance(model, X_train, X_test, y_test, timestamps_test=None):
    """
    æ—¶åºæ•°æ®ä¸“ç”¨è¯„ä¼°æŒ‡æ ‡
    Time-series specific evaluation metrics
    """
    # åŸºç¡€æ€§èƒ½æŒ‡æ ‡
    y_pred = model.predict(X_test)
    y_scores = model.decision_function(X_test)

    metrics = {
        'auc': roc_auc_score(y_test, y_scores),
        'precision': precision_score(y_test, y_pred),
        'recall': recall_score(y_test, y_pred),
        'f1': f1_score(y_test, y_pred)
    }

    # æ—¶åºä¸“ç”¨æŒ‡æ ‡: æ£€æµ‹å»¶è¿Ÿ (Detection Delay)
    # è®¡ç®—ä»å¼‚å¸¸å¼€å§‹åˆ°è¢«æ£€æµ‹å‡ºçš„å¹³å‡å»¶è¿Ÿ
    if timestamps_test is not None and len(timestamps_test) == len(y_test):
        anomaly_indices = np.where(y_test == 1)[0]
        detected_indices = np.where(y_pred == 1)[0]

        # ç®€åŒ–è®¡ç®—ï¼šç»Ÿè®¡æœ‰å¤šå°‘å¼‚å¸¸åœ¨åˆç†æ—¶é—´çª—å£å†…è¢«æ£€æµ‹
        metrics['detection_window_5min'] = 0
        for anomaly_idx in anomaly_indices:
            # æ£€æŸ¥åç»­5ä¸ªæ—¶é—´ç‚¹å†…æ˜¯å¦æ£€æµ‹åˆ°
            window = detected_indices[(detected_indices >= anomaly_idx) & (detected_indices < anomaly_idx + 5)]
            if len(window) > 0:
                metrics['detection_window_5min'] += 1

        if len(anomaly_indices) > 0:
            metrics['detection_window_5min'] /= len(anomaly_indices)

    # è¯¯æŠ¥ç‡ (False Positive Rate) - æ—¶åºæ•°æ®ä¸­çš„å…³é”®æŒ‡æ ‡
    tn = np.sum((y_test == 0) & (y_pred == 0))
    fp = np.sum((y_test == 0) & (y_pred == 1))
    metrics['fpr'] = fp / (fp + tn) if (fp + tn) > 0 else 0

    return metrics


def compare_algorithms(X_train, X_test, y_test, contamination=0.05, enable_time_series_features=False):
    """
    æ¯”è¾ƒå¤šä¸ªå¼‚å¸¸æ£€æµ‹ç®—æ³• (é’ˆå¯¹å¤§è§„æ¨¡æ—¶åºé‡‘èæ•°æ®ä¼˜åŒ–)
    å‚æ•°:
    - enable_time_series_features: æ˜¯å¦å¯ç”¨æ—¶åºç‰¹å¾å·¥ç¨‹ (ä¼šå¢åŠ ç‰¹å¾ç»´åº¦)
    """
    print(f"æ•°æ®è§„æ¨¡: è®­ç»ƒé›† {X_train.shape}, æµ‹è¯•é›† {X_test.shape}")
    print(f"æ—¶åºç‰¹å¾å·¥ç¨‹: {'å¯ç”¨' if enable_time_series_features else 'ç¦ç”¨'}")
    # å®šä¹‰ç®—æ³• - é’ˆå¯¹å¤§è§„æ¨¡æ—¶åºé‡‘èæ•°æ®ä¼˜åŒ–
    # ä¼˜å…ˆè€ƒè™‘: 1) å¯æ‰©å±•æ€§ 2) è®­ç»ƒé€Ÿåº¦ 3) åœ¨çº¿å­¦ä¹ èƒ½åŠ›
    algorithms = {
        # â˜† æ¨èç”¨äºå¤§è§„æ¨¡æ—¶åºæ•°æ®çš„ç®—æ³•
        'Isolation Forest': IForest(
            contamination=contamination,
            random_state=42,
            n_estimators=100,  # ä»200é™è‡³100ä»¥åŠ é€Ÿ
            max_samples='auto',  # è‡ªåŠ¨é‡‡æ ·ï¼Œé€‚åˆå¤§æ•°æ®
            n_jobs=-1 # å¹¶è¡Œè®­ç»ƒ
        ),
        'ECOD': ECOD(
            contamination=contamination,
            n_jobs=-1 # å¹¶è¡Œè®¡ç®—
        ),
        'HBOS': HBOS(
            contamination=contamination,
            n_bins=15,  # ä»20é™è‡³15ä»¥åŠ é€Ÿ
            tol=0.5  # å®¹å·®è®¾ç½®
        ),
        'COPOD': COPOD(
            contamination=contamination,
            n_jobs=-1
        ),
        # â—† ä¸­ç­‰æ¨è - æ€§èƒ½è‰¯å¥½ä½†å¯èƒ½åœ¨è¶…å¤§è§„æ¨¡æ•°æ®ä¸Šè¾ƒæ…¢
        'PCA': PCA(
            contamination=contamination,
            n_components=min(8, X_train.shape[1] // 2)  # åŠ¨æ€è®¾ç½®ä¸»æˆåˆ†æ•°
        ),
        # â–¼ ä¸æ¨èç”¨äºå¤§è§„æ¨¡æ•°æ® - ä»…ä½œå¯¹æ¯”
        'KNN': KNN(contamination=contamination, n_neighbors=10, n_jobs=-1),
        'LOF': LOF(contamination=contamination, n_neighbors=20, n_jobs=-1),
    }

    # å¯é€‰: æ·»åŠ æ·±åº¦å­¦ä¹ ç®—æ³• (é€‚åˆç¦»çº¿æ‰¹å¤„ç†)
    if AUTOENCODER_AVAILABLE:
        try:
            algorithms['AutoEncoder'] = AutoEncoder(
                contamination=contamination,
                hidden_neuron_list=[X_train.shape[1], max(10, X_train.shape[1]//2), max(10, X_train.shape[1]//2), X_train.shape[1]],
                epoch_num=30,  # ä»50é™è‡³30ä»¥åŠ é€Ÿ
                batch_size=64,  # ä»32å¢è‡³64ä»¥æå‡ååé‡
                verbose=0,
                random_state=42
            )
            print("  âœ… AutoEncoder å·²å¯ç”¨ (é€‚åˆç¦»çº¿åˆ†æ) ")
        except Exception as e:
            print(f"  âš ï¸ AutoEncoder åˆå§‹åŒ–å¤±è´¥: {str(e)}")

    results = []
    print("\nå¼€å§‹ç®—æ³•æ¯”è¾ƒ (é’ˆå¯¹å¤§è§„æ¨¡æ—¶åºæ•°æ®ä¼˜åŒ–) ...")
    print("-" * 80)

    for name, model in algorithms.items():
        print(f"\nè®­ç»ƒ {name}...")
        start_time = time.time()
        try:
            # è®­ç»ƒ
            model.fit(X_train)
            # é¢„æµ‹
            y_pred = model.predict(X_test)
            y_scores = model.decision_function(X_test)
            # è®¡ç®—æŒ‡æ ‡
            training_time = time.time() - start_time
            # é¢„æµ‹æ—¶é—´
            start_pred = time.time()
            _ = model.predict(X_test[:100])
            prediction_time = (time.time() - start_pred) / 100 * 1000  # ms per sample

            auc = roc_auc_score(y_test, y_scores)
            precision = precision_score(y_test, y_pred)
            recall = recall_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)

            # å¤§æ•°æ®ç‰¹å®šæŒ‡æ ‡: ååé‡ (æ¯ç§’å¤„ç†æ ·æœ¬æ•°)
            throughput = len(X_test) / (time.time() - start_pred) if (time.time() - start_pred) > 0 else 0

            # å†…å­˜æ•ˆç‡è¯„ä¼° (ç®€åŒ–ç‰ˆ)
            memory_friendly = "æ˜¯" if name in ['Isolation Forest', 'ECOD', 'HBOS', 'COPOD'] else "å¦"
            online_learning = "æ”¯æŒ" if name in ['HBOS'] else "ä¸æ”¯æŒ"
            results.append({
                'Algorithm': name,
                'AUC-ROC': auc,
                'Precision': precision,
                'Recall': recall,
                'F1-Score': f1,
                'Training Time (s)': training_time,
                'Prediction Time (ms)': prediction_time,
                'Throughput (samples/s)': throughput,
                'Memory Efficient': memory_friendly,
                'Scalability': 'ä¼˜ç§€' if name in ['Isolation Forest', 'ECOD'] else 'ä¸€èˆ¬' if name in ['HBOS', 'COPOD', 'PCA'] else 'å·®'
            })
            print(f"  AUC: {auc:.4f}, F1: {f1:.4f}, è®­ç»ƒ: {training_time:.2f}s, ååé‡: {throughput:.0f} samples/s")

        except Exception as e:
            print(f"  âŒ å¤±è´¥: {str(e)}")
            continue

    return pd.DataFrame(results)


def plot_comparison_results(results_df, output_path='algorithm_comparison.png'):
    """
    å¯è§†åŒ–æ¯”è¾ƒç»“æœ
    """
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # 1. æ€§èƒ½æŒ‡æ ‡æ¯”è¾ƒ
    metrics = ['AUC-ROC', 'Precision', 'Recall', 'F1-Score']
    results_plot = results_df.set_index('Algorithm')[metrics]

    ax1 = axes[0, 0]
    results_plot.plot(kind='bar', ax=ax1, width=0.8)
    ax1.set_title('Performance Metrics Comparison', fontsize=14, fontweight='bold')
    ax1.set_ylabel('Score', fontsize=12)
    ax1.legend(loc='lower right')
    ax1.grid(axis='y', alpha=0.3)
    ax1.set_ylim([0, 1.1])

    # 2. AUC-ROC æ’å
    ax2 = axes[0, 1]
    sorted_auc = results_df.sort_values('AUC-ROC', ascending=True)
    colors = plt.cm.RdYlGn(sorted_auc['AUC-ROC'].values)
    ax2.barh(sorted_auc['Algorithm'], sorted_auc['AUC-ROC'], color=colors)
    ax2.set_xlabel('AUC-ROC Score', fontsize=12)
    ax2.set_title('AUC-ROC Ranking', fontsize=14, fontweight='bold')
    ax2.grid(axis='x', alpha=0.3)

    # 3. è®­ç»ƒæ—¶é—´æ¯”è¾ƒ
    ax3 = axes[1, 0]
    sorted_time = results_df.sort_values('Training Time (s)')
    ax3.bar(range(len(sorted_time)), sorted_time['Training Time (s)'],
            color='steelblue', alpha=0.7)
    ax3.set_xticks(range(len(sorted_time)))
    ax3.set_xticklabels(sorted_time['Algorithm'], rotation=45, ha='right')
    ax3.set_ylabel('Training Time (seconds)', fontsize=12)
    ax3.set_title('Training Time Comparison', fontsize=14, fontweight='bold')
    ax3.grid(axis='y', alpha=0.3)

    # 4. Precision vs Recall
    ax4 = axes[1, 1]
    for idx, row in results_df.iterrows():
        ax4.scatter(row['Recall'], row['Precision'], s=200, alpha=0.6)
        ax4.annotate(row['Algorithm'],
                     (row['Recall'], row['Precision']),
                     fontsize=9, ha='center')
    ax4.set_xlabel('Recall', fontsize=12)
    ax4.set_ylabel('Precision', fontsize=12)
    ax4.set_title('Precision vs Recall Trade-off', fontsize=14, fontweight='bold')
    ax4.grid(alpha=0.3)
    ax4.set_xlim([0, 1.1])
    ax4.set_ylim([0, 1.1])

    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"\nğŸ“Š å›¾è¡¨å·²ä¿å­˜: {output_path}")

    return fig
